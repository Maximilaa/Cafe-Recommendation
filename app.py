# -*- coding: utf-8 -*-
"""app
Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/16gW4FijDtLhFvXKEszsGFFbm83PYFFSf
"""

import streamlit as st
import pandas as pd
import torch
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.metrics.pairwise import cosine_similarity
from huggingface_hub import hf_hub_download
from langdetect import detect, DetectorFactory

# Ensure consistent language detection results
DetectorFactory.seed = 0

# =========================
# CONFIG
# =========================
st.set_page_config(
    page_title="Cafe Recommender System",
    layout="wide"
)

# Parameters as per Chapter IV
ALPHA = 0.7   
TOP_N = 5
MAX_LEN = 320 # As per cek.pdf

# =========================
# LOAD ASSETS
# =========================
@st.cache_resource
def load_assets():
    REPO_ID = "lattezice/cafe-sentimen-bert"
    with st.spinner("‚è≥ Synchronizing Data with Colab..."):
        # Load aligned CSV
        csv_path = hf_hub_download(repo_id=REPO_ID, filename="processed_coffee.csv")
        df = pd.read_csv(csv_path)

        # REVISION: Map "PA" to "Pennsylvania"
        df['state'] = df['state'].replace('PA', 'Pennsylvania')

        model_path = hf_hub_download(repo_id=REPO_ID, filename="models/best_model.pt")
        emb_path = hf_hub_download(repo_id=REPO_ID, filename="cafe_embedding.npy")
        sent_path = hf_hub_download(repo_id=REPO_ID, filename="sentiment_score.npy")
        
        cafe_emb = np.load(emb_path)      
        sentiment_score = np.load(sent_path)

    tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
    model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
    model.to(device).eval()

    return df, tokenizer, model, cafe_emb, sentiment_score, device

# Asset Execution
try:
    df, tokenizer, model, cafe_emb_matrix, sentiment_score_vec, device = load_assets()
except Exception as e:
    st.error(f"Failed to load assets: {e}")
    st.stop()

# =========================
# HELPER FUNCTIONS
# =========================
def encode_text(text):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=MAX_LEN
    ).to(device)

    with torch.no_grad():
        outputs = model.bert(**inputs) 
        # Extract [CLS] token for review representation
        emb = outputs.last_hidden_state[:, 0, :]  

    return emb.cpu().numpy().flatten()

def is_english(text):
    try:
        return detect(text) == 'en'
    except:
        return False

# =========================
# UI (English Version)
# =========================
st.title("‚òï Cafe Recommender System")
st.markdown("Recommendation System based on Semantic Embedding & Sentiment Analysis")

with st.form("recommender_form"):
    user_text = st.text_area(
        "Cafe Preferences (Must be in English, e.g., 'cozy quiet place for studying')",
        height=120
    )

    col1, col2 = st.columns(2)
    with col1:
        city = st.selectbox("City", sorted(df["city"].dropna().unique()))
    with col2:
        # This will now display "Pennsylvania"
        state = st.selectbox("State", sorted(df["state"].dropna().unique()))

    submitted = st.form_submit_button("Get Recommendations")

# =========================
# RECOMMENDATION LOGIC
# =========================
if submitted:
    if user_text.strip() == "":
        st.warning("Please enter your cafe preferences first.")
    elif not is_english(user_text):
        st.error("‚ùå Invalid input: Please use English for your preferences.")
    else:
        with st.spinner("Calculating hybrid scores..."):
            df_unique = df.copy()

            # Location filtering logic
            mask = (df_unique['city'].str.lower() == city.lower()) & \
                   (df_unique['state'].str.lower() == state.lower())
            indices = np.where(mask)[0]

            if len(indices) == 0:
                st.error(f"No cafes found in {city}, {state}.")
            else:
                # Slicing assets
                emb_filtered = cafe_emb_matrix[indices]
                sent_filtered = sentiment_score_vec[indices]
                df_filtered = df_unique.iloc[indices].copy()

                # User Preference Embedding
                user_emb = encode_text(user_text).reshape(1, -1)

                # Hybrid Score Calculation
                # Formula: $Score = (0.7 \times \text{Semantic}) + (0.3 \times \text{Sentiment\_norm})$
                # where $\text{Sentiment\_norm} = \frac{(\text{Sentiment Score} + 1)}{2}$
                sim_sem = cosine_similarity(user_emb, emb_filtered)[0]
                sent_norm = (sent_filtered + 1) / 2
                hybrid_score = (ALPHA * sim_sem) + ((1 - ALPHA) * sent_norm)

                # Ranking
                df_filtered["hybrid_score"] = hybrid_score
                df_filtered = df_filtered.sort_values("hybrid_score", ascending=False).head(TOP_N)
                
                df_filtered.insert(0, "Rank", range(1, 1 + len(df_filtered)))

                # Formatting output
                df_filtered["Rating"] = df_filtered["cafe_rating"].map(lambda x: "{:.1f}".format(float(x)))
                df_filtered["Match Score"] = df_filtered["hybrid_score"].map(lambda x: "{:.3f}".format(float(x)))

                # Column Selection
                display_cols = ["Rank", "cafe_name", "Rating", "city", "state", "Match Score"]
                df_display = df_filtered[display_cols].copy()
                df_display.columns = ["Rank", "Cafe Name", "Rating", "City", "State", "Match Score"]

                st.subheader("üéØ Top Recommendations")
                
                # Display without index per request
                st.dataframe(
                    df_display, 
                    hide_index=True, 
                    use_container_width=True
                )
                
                st.success("Analysis complete!")
